{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219e3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to use the Utils.py file. Since they are not in the same folder. \n",
    "# Mapping the current working directory to the main path.\n",
    "import os, sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3338a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98357b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cpu\") #getDeviceType(DLFrameworks.PyTorch)\n",
    "print(f\"Running on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c712d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2cc0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), # Since our images are RGB, \n",
    "                          (0.5,0.5,0.5)) # we are using 3 values for mean and standard deviation\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84ccc7",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b92e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset_exists = Path(\"./data/cifar-10-python.tar.gz\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246a732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"./data\",\n",
    "                                         train=True,\n",
    "                                         transform=transform,\n",
    "                                         download= not dataset_exists)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d47d93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Dataset\n",
    "val_set = torchvision.datasets.CIFAR10(root=\"./data\",\n",
    "                                       train=False,\n",
    "                                       transform=transform,\n",
    "                                       download=not dataset_exists)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c59aa",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ee42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Net(nn.Module):\n",
    "    def __init__(self, name: str, drop_out_prob: int, num_classes: int):\n",
    "        super(CIFAR10Net, self).__init__()\n",
    "\n",
    "        self.model_name = name\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.drop = nn.Dropout(p= drop_out_prob)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1) \n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee1f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR10Net(name=\"CIFAR-10\", drop_out_prob=0.5, num_classes=10).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "302390b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr= LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24095b78",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, optimizer, criterion, train_loader, EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader,\n",
    "                            desc= f\"Epoch: {epoch + 1} / {EPOCHS}\",\n",
    "                            unit=\"batch\")\n",
    "\n",
    "\n",
    "        for i, (images,labels) in enumerate(progress_bar, 1):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            output = model(images)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(avg_loss=running_loss / i)\n",
    "        \n",
    "        total_loss.append(running_loss)\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cca9c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 20: 100%|██████████| 3125/3125 [01:19<00:00, 39.46batch/s, avg_loss=1.3] \n",
      "Epoch: 2 / 20: 100%|██████████| 3125/3125 [01:20<00:00, 38.78batch/s, avg_loss=0.987]\n",
      "Epoch: 3 / 20: 100%|██████████| 3125/3125 [01:25<00:00, 36.51batch/s, avg_loss=0.884]\n",
      "Epoch: 4 / 20: 100%|██████████| 3125/3125 [01:19<00:00, 39.53batch/s, avg_loss=0.823]\n",
      "Epoch: 5 / 20: 100%|██████████| 3125/3125 [01:28<00:00, 35.38batch/s, avg_loss=0.781]\n",
      "Epoch: 6 / 20: 100%|██████████| 3125/3125 [01:20<00:00, 38.99batch/s, avg_loss=0.745]\n",
      "Epoch: 7 / 20: 100%|██████████| 3125/3125 [01:18<00:00, 39.75batch/s, avg_loss=0.719]\n",
      "Epoch: 8 / 20: 100%|██████████| 3125/3125 [01:23<00:00, 37.49batch/s, avg_loss=0.694]\n",
      "Epoch: 9 / 20: 100%|██████████| 3125/3125 [01:25<00:00, 36.71batch/s, avg_loss=0.674]\n",
      "Epoch: 10 / 20: 100%|██████████| 3125/3125 [01:31<00:00, 34.05batch/s, avg_loss=0.653]\n",
      "Epoch: 11 / 20: 100%|██████████| 3125/3125 [01:28<00:00, 35.36batch/s, avg_loss=0.637]\n",
      "Epoch: 12 / 20: 100%|██████████| 3125/3125 [01:27<00:00, 35.57batch/s, avg_loss=0.62] \n",
      "Epoch: 13 / 20: 100%|██████████| 3125/3125 [01:32<00:00, 33.86batch/s, avg_loss=0.605]\n",
      "Epoch: 14 / 20: 100%|██████████| 3125/3125 [01:31<00:00, 34.32batch/s, avg_loss=0.594]\n",
      "Epoch: 15 / 20: 100%|██████████| 3125/3125 [01:27<00:00, 35.71batch/s, avg_loss=0.583]\n",
      "Epoch: 16 / 20: 100%|██████████| 3125/3125 [01:25<00:00, 36.59batch/s, avg_loss=0.574]\n",
      "Epoch: 17 / 20: 100%|██████████| 3125/3125 [01:30<00:00, 34.54batch/s, avg_loss=0.56] \n",
      "Epoch: 18 / 20: 100%|██████████| 3125/3125 [01:37<00:00, 32.04batch/s, avg_loss=0.555]\n",
      "Epoch: 19 / 20: 100%|██████████| 3125/3125 [01:33<00:00, 33.34batch/s, avg_loss=0.549]\n",
      "Epoch: 20 / 20: 100%|██████████| 3125/3125 [01:31<00:00, 34.21batch/s, avg_loss=0.534]\n"
     ]
    }
   ],
   "source": [
    "total_loss = train(model, optimizer, criterion, train_loader, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb32b5",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3191f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    progress_bar = tqdm(test_loader,\n",
    "                        desc=f\"Test Dataset\",\n",
    "                        unit=\"batch\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(progress_bar, 1):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "403f1628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Dataset: 100%|██████████| 625/625 [00:21<00:00, 29.70batch/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701fddd3",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb077436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cafe17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(drop_out_prob, channels) -> nn.Module:\n",
    "    class CIFAR10Net(nn.Module):\n",
    "        def __init__(self, name: str, drop_out_prob: int, num_classes: int):\n",
    "            super(CIFAR10Net, self).__init__()\n",
    "\n",
    "            self.model_name = name\n",
    "            self.conv1 = nn.Conv2d(in_channels=3, out_channels=channels, kernel_size=3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(in_channels=channels, out_channels=channels * 2, kernel_size=3, padding=1)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.drop = nn.Dropout(p= drop_out_prob)\n",
    "\n",
    "            self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "            self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "            x = torch.flatten(x, 1) \n",
    "\n",
    "            x = self.fc1(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "    \n",
    "    model = CIFAR10Net(name=\"CIFAR-10Net\", drop_out_prob=drop_out_prob, num_classes=10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbe5e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,optimizer, criterion, train_loader, DEVICE, EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader,\n",
    "                            desc=f\"{epoch + 1} / {EPOCHS} EPOCHS\",\n",
    "                            unit=\"batch\")\n",
    "        \n",
    "        for i, images, labels in enumerate(progress_bar, 1):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            output = model(images)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(avg_loss=running_loss / i)\n",
    "        \n",
    "        total_loss.append(running_loss)\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af14b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, DEVICE):\n",
    "\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    progress_bar = tqdm(val_loader,\n",
    "                        desc= \"Validating\",\n",
    "                        unit=\"batch\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(progress_bar, 1):\n",
    "\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ed8b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, train_loader, val_loader, DEVICE):\n",
    "        \n",
    "    learning_rate = trial.suggest_float('learning_rate',1e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.7)\n",
    "    channels = trial.suggest_categorical('channels', [32, 64, 128])\n",
    "\n",
    "    model = make_model(drop_out_prob=dropout, channels=channels).to(DEVICE)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train(model, optimizer, criterion, train_loader,5)\n",
    "    accuracy = evaluate(model, val_loader, DEVICE)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02c663c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-08 22:37:14,754] A new study created in memory with name: no-name-ad271db4-b7f6-437b-ae7b-18115409247d\n",
      "Epoch: 1 / 5: 100%|██████████| 3125/3125 [01:12<00:00, 42.88batch/s, avg_loss=1.27]\n",
      "Epoch: 2 / 5: 100%|██████████| 3125/3125 [01:09<00:00, 44.69batch/s, avg_loss=0.935]\n",
      "Epoch: 3 / 5: 100%|██████████| 3125/3125 [01:13<00:00, 42.28batch/s, avg_loss=0.809]\n",
      "Epoch: 4 / 5: 100%|██████████| 3125/3125 [01:16<00:00, 40.99batch/s, avg_loss=0.723]\n",
      "Epoch: 5 / 5: 100%|██████████| 3125/3125 [01:15<00:00, 41.56batch/s, avg_loss=0.658]\n",
      "Validating: 100%|██████████| 625/625 [00:19<00:00, 32.42batch/s] \n",
      "[I 2025-07-08 22:43:42,254] Trial 0 finished with value: 0.7148 and parameters: {'learning_rate': 0.0003552405010988866, 'dropout': 0.6443597379302418, 'channels': 32}. Best is trial 0 with value: 0.7148.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 5:   0%|          | 0/3125 [00:16<?, ?batch/s]\n",
      "[W 2025-07-08 22:43:58,585] Trial 1 failed with parameters: {'learning_rate': 0.000930110634862718, 'dropout': 0.6678249003029241, 'channels': 128} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (16x16384 and 4096x256)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mithesh/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/17/js2qkwqd7cqdm6wdqkfsnpm00000gn/T/ipykernel_27062/2615564000.py\", line 11, in objective\n",
      "    train(model, optimizer, criterion, train_loader,5)\n",
      "  File \"/var/folders/17/js2qkwqd7cqdm6wdqkfsnpm00000gn/T/ipykernel_27062/342004722.py\", line 15, in train\n",
      "    output = model(images)\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"/Users/mithesh/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mithesh/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/17/js2qkwqd7cqdm6wdqkfsnpm00000gn/T/ipykernel_27062/1401314847.py\", line 27, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/Users/mithesh/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mithesh/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mithesh/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (16x16384 and 4096x256)\n",
      "[W 2025-07-08 22:43:58,597] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x16384 and 4096x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m objective_with_args = partial(objective, train_loader=train_loader, val_loader=val_loader, DEVICE=DEVICE)\n\u001b[32m      5\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_with_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest trial:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m trial = study.best_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial, train_loader, val_loader, DEVICE)\u001b[39m\n\u001b[32m      8\u001b[39m optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n\u001b[32m      9\u001b[39m criterion = nn.CrossEntropyLoss()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m accuracy = evaluate(model, val_loader, DEVICE)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, criterion, train_loader, EPOCHS)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (images,labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(progress_bar, \u001b[32m1\u001b[39m):\n\u001b[32m     14\u001b[39m     images, labels = images.to(DEVICE), labels.to(DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     loss = criterion(output, labels)\n\u001b[32m     18\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mmake_model.<locals>.CIFAR10Net.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     23\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool(x)\n\u001b[32m     25\u001b[39m x = torch.flatten(x, \u001b[32m1\u001b[39m) \n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m x = \u001b[38;5;28mself\u001b[39m.fc2(x)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CodeToGreatness/NeuroForge/Projects/myenv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (16x16384 and 4096x256)"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "objective_with_args = partial(objective, train_loader=train_loader, val_loader=val_loader, DEVICE=DEVICE)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_with_args, n_trials=5)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"Accuracy: {trial.value:.4f}\")\n",
    "print(\"Params:\")\n",
    "for k, v in trial.params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
